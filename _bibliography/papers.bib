---
---

@string{aps = {American Physical Society,}}


@article{Linot2025,
	Abstract = {A wide range of techniques exist for extracting the dominant flow dynamics and features about steady, or periodic base flows. However, there have been limited efforts in extracting the dominant dynamics about unsteady, aperiodic base flow. These flows appear in many applications such as when there is a sudden change in the flow rate through a pipe, when an airfoil experiences stall, or when a vortex forms. For these unsteady flows, it is valuable to know not only the dynamics of the base flow but also the features that form around this base flow. Here, we discuss the current state of research on extracting important flow structures and their dynamics in such cases with time-varying base flows. In particular, we consider data-driven decompositions, operator-based methods, causality analysis, and some other approaches. We also offer an outlook and call attention to key areas that require future efforts.},
	Author = {Linot, Alec J and Lopez-Doriga, Barbara and Zhong, Yonghong and Taira, Kunihiko},
	Doi = {10.1088/1873-7005/ade338},
	Journal = {Fluid Dynamics Research},
	Month = {June},
	Number = {3},
	Pages = {031401},
	Publisher = {IOP Publishing},
	Title = {Extracting dominant dynamics about unsteady base flows},
	Url = {https://dx.doi.org/10.1088/1873-7005/ade338},
	Volume = {57},
	Year = {2025},
	Bdsk-Url-1 = {https://dx.doi.org/10.1088/1873-7005/ade338}}


@article{Linot2020,
  title = {Deep learning to discover and predict dynamics on an inertial manifold},
  author = {Linot, Alec J. and Graham, Michael D.},
  journal = {Phys. Rev. E},
  volume = {101},
  issue = {6},
  pages = {062209},
  numpages = {8},
  year = {2020},
  month = {June},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.101.062209},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.101.062209}
}

@article{ODENet,
author = {Linot,Alec J.  and Graham,Michael D. },
title = {Data-driven reduced-order modeling of spatiotemporal chaos with neural ordinary differential equations},
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
volume = {32},
number = {7},
pages = {073110},
year = {2022},
doi = {10.1063/5.0069536},
URL = { 
        https://doi.org/10.1063/5.0069536
    
},
eprint = { 
        https://doi.org/10.1063/5.0069536
}
}

@article{NODERL,
author = {Zeng, Kevin  and Linot, Alec J.  and Graham, Michael D. },
title = {Data-driven control of spatiotemporal chaos with reduced-order neural ODE-based models and reinforcement learning},
journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
volume = {478},
number = {2267},
pages = {20220297},
year = {2022},
doi = {10.1098/rspa.2022.0297},
URL = {https://royalsocietypublishing.org/doi/abs/10.1098/rspa.2022.0297},
eprint = {https://royalsocietypublishing.org/doi/pdf/10.1098/rspa.2022.0297}
,
    abstract = { Deep reinforcement learning (RL) is a data-driven method capable of discovering complex control strategies for high-dimensional systems, making it promising for flow control applications. In particular, the present work is motivated by the goal of reducing energy dissipation in turbulent flows, and the example considered is the spatiotemporally chaotic dynamics of the Kuramoto–Sivashinsky equation (KSE). A major challenge associated with RL is that substantial training data must be generated by repeatedly interacting with the target system, making it costly when the system is computationally or experimentally expensive. We mitigate this challenge in a data-driven manner by combining dimensionality reduction via an autoencoder with a neural ODE framework to obtain a low-dimensional dynamical model from just a limited data set. We substitute this data-driven reduced-order model (ROM) in place of the true system during RL training to efficiently estimate the optimal policy, which can then be deployed on the true system. For the KSE actuated with localized forcing (‘jets’) at four locations, we demonstrate that we are able to learn a ROM that accurately captures the actuated dynamics as well as the underlying natural dynamics just from snapshots of the KSE experiencing random actuations. Using this ROM and a control objective of minimizing dissipation and power cost, we extract a control policy from it using deep RL. We show that the ROM-based control strategy translates well to the true KSE and highlight that the RL agent discovers and stabilizes an underlying forced equilibrium solution of the KSE system. We show that this forced equilibrium captured in the ROM and discovered through RL is related to an existing known equilibrium solution of the natural KSE. }
}

@article{Stability, title={On the laminar solutions and stability of accelerating and decelerating channel flows},selected={true}, volume={999}, DOI={10.1017/jfm.2024.709}, journal={Journal of Fluid Mechanics}, author={Linot, Alec J. and Schmid, Peter J. and Taira, Kunihiko}, year={2024}, pages={A43}}

@article{SymmROM,
  title = {Building symmetries into data-driven manifold dynamics models for complex flows},
  author = {P\'erez De Jes\'us, Carlos E. and Linot, Alec J. and Graham, Michael D.},
  journal = {Phys. Rev. Fluids},
  volume = {10},
  issue = {6},
  pages = {064401},
  numpages = {28},
  year = {2025},
  month = {Jun},
  publisher = {American Physical Society},
  doi = {10.1103/ts3k-flx6},
  url = {https://link.aps.org/doi/10.1103/ts3k-flx6}
}


@article{PipeDManD,
  title = {Dynamics of a Data-Driven Low-Dimensional Model of Turbulent Minimal Pipe Flow},
  author = {Constante-Amores, C. Ricardo and Linot, Alec J. and Graham, Michael D.},
  journal = {arXiv preprint 2408.03135},
  volume = {},
  issue = {},
  pages = {},
  numpages = {},
  year = {2024},
  month = {},
  publisher = {},
  doi = {},
  url = {}
}

@article{DistROM,
  title = {Data-driven prediction of large-scale spatiotemporal chaos with distributed low-dimensional models},
  author = {Constante-Amores, C. Ricardo and Linot, Alec J. and Graham, Michael D.},
  journal = {arXiv preprint 2410.01238},
  volume = {},
  issue = {},
  pages = {},
  numpages = {},
  year = {2024},
  month = {},
  publisher = {},
  doi = {},
  url = {}
}

@article{HierGNN,
  title = {Hierarchical equivariant graph neural networks for forecasting collective motion in vortex clusters and microswimmers},
  author = {Linot, Alec J. and Hang, Haotian and Kanso, Eva and Taira, Kunihiko},
  journal = {arXiv preprint 2501.00626},
  volume = {},
  issue = {},
  pages = {},
  numpages = {},
  year = {2024},
  month = {},
  publisher = {},
  doi = {},
  url = {}
}


@article{Hiroshi,
author = {Hiroshi Omichi and Alec J. Linot and Koji Fukagata and Kunihiko Taira},
title = {Reinforcement Learning With Symmetry Reduction for Rotating Cylinder Wakes: Finding Unstable Low-Drag Fixed Points},
journal = {AIAA SCITECH 2025 Forum},
doi = {10.2514/6.2025-1299},
URL = {https://arc.aiaa.org/doi/abs/10.2514/6.2025-1299},
eprint = {https://arc.aiaa.org/doi/pdf/10.2514/6.2025-1299},  year = {2025},
month={January}
}


@article{OptDec,
  title = {Mitigating transient growth in decelerating flows with optimal deceleration profiles},
  author = {Linot, Alec J. and Taira, Kunihiko},
  journal = {(to be submitted)},
  volume = {},
  issue = {},
  pages = {},
  numpages = {},
  year = {2025},
  month = {},
  publisher = {},
  doi = {},
  url = {}
}

@article{Ricardo2023,
    author = {Ricardo Constante-Amores, C. and Linot, Alec J. and Graham, Michael D.},
    title = "{Enhancing predictive capabilities in data-driven dynamical modeling with automatic differentiation: Koopman and neural ODE approaches}",
    journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
    volume = {34},
    number = {4},
    pages = {043119},
    year = {2024},
    month = {04},
    abstract = "{Data-driven approximations of the Koopman operator are promising for predicting the time evolution of systems characterized by complex dynamics. Among these methods, the approach known as extended dynamic mode decomposition with dictionary learning (EDMD-DL) has garnered significant attention. Here, we present a modification of EDMD-DL that concurrently determines both the dictionary of observables and the corresponding approximation of the Koopman operator. This innovation leverages automatic differentiation to facilitate gradient descent computations through the pseudoinverse. We also address the performance of several alternative methodologies. We assess a “pure” Koopman approach, which involves the direct time-integration of a linear, high-dimensional system governing the dynamics within the space of observables. Additionally, we explore a modified approach where the system alternates between spaces of states and observables at each time step—this approach no longer satisfies the linearity of the true Koopman operator representation. For further comparisons, we also apply a state-space approach (neural ordinary differential equations). We consider systems encompassing two- and three-dimensional ordinary differential equation systems featuring steady, oscillatory, and chaotic attractors, as well as partial differential equations exhibiting increasingly complex and intricate behaviors. Our framework significantly outperforms EDMD-DL. Furthermore, the state-space approach offers superior performance compared to the “pure” Koopman approach where the entire time evolution occurs in the space of observables. When the temporal evolution of the Koopman approach alternates between states and observables at each time step, however, its predictions become comparable to those of the state-space approach.}",
    issn = {1054-1500},
    doi = {10.1063/5.0180415},
    url = {https://doi.org/10.1063/5.0180415},
    eprint = {https://pubs.aip.org/aip/cha/article-pdf/doi/10.1063/5.0180415/19867431/043119\_1\_5.0180415.pdf},
}


@article{Couette, title={Dynamics of a data-driven low-dimensional model of turbulent minimal {C}ouette flow}, volume={973}, DOI={10.1017/jfm.2023.720}, journal={Journal of Fluid Mechanics}, publisher={Cambridge University Press}, author={Linot, Alec J. and Graham, Michael D.}, year={2023}, pages={A42},selected={true}}

@article{NODERLCouette,
title = {Turbulence control in plane {Couette} flow using low-dimensional neural ODE-based models and deep reinforcement learning},
journal = {International Journal of Heat and Fluid Flow},
volume = {101},
pages = {109139},
year = {2023},
issn = {0142-727X},
doi = {https://doi.org/10.1016/j.ijheatfluidflow.2023.109139},
url = {https://www.sciencedirect.com/science/article/pii/S0142727X23000383},
author = {Alec J. Linot and Kevin Zeng and Michael D. Graham},
selected={true},
keywords = {Turbulent shear flow, Flow control, Coherent structures, Machine learning, Reduced- order modeling},
abstract = {The high dimensionality and complex dynamics of turbulent flows remain an obstacle to the discovery and implementation of control strategies. Deep reinforcement learning (RL) is a promising avenue for overcoming these obstacles, but requires a training phase in which the RL agent iteratively interacts with the flow environment to learn a control policy, which can be prohibitively expensive when the environment involves slow experiments or large-scale simulations. We overcome this challenge using a framework we call “DManD-RL” (data-driven manifold dynamics-RL), which generates a data-driven low-dimensional model of our system that we use for RL training. With this approach, we seek to minimize drag in a direct numerical simulation (DNS) of a turbulent minimal flow unit of plane Couette flow at Re=400 using two slot jets on one wall. We obtain, from DNS data with O(105) degrees of freedom, a 25-dimensional DManD model of the dynamics by combining an autoencoder and neural ordinary differential equation. Using this model as the environment, we train an RL control agent, yielding a 440-fold speedup over training on the DNS, with equivalent control performance. The agent learns a policy that laminarizes 84% of unseen DNS test trajectories within 900 time units, significantly outperforming classical opposition control (58%), despite the actuation authority being much more restricted. The agent often achieves laminarization through a counterintuitive strategy that drives the formation of two low-speed streaks, with a spanwise wavelength that is too small to be self-sustaining. The agent demonstrates the same performance when we limit observations to wall shear rate.}
}


@article{LinNODE,
title = {Stabilized neural ordinary differential equations for long-time forecasting of dynamical systems},
journal = {Journal of Computational Physics},
volume = {474},
pages = {111838},
year = {2023},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2022.111838},
url = {https://www.sciencedirect.com/science/article/pii/S0021999122009019},
author = {Alec J. Linot and Joshua W. Burby and Qi Tang and Prasanna Balaprakash and Michael D. Graham and Romit Maulik},
keywords = {Neural ordinary differential equations, Reduced-order models, Partial differential equations},
selected={true},
abstract = {In data-driven modeling of spatiotemporal phenomena careful consideration is needed in capturing the dynamics of the high wavenumbers. This problem becomes especially challenging when the system of interest exhibits shocks or chaotic dynamics. We present a data-driven modeling method that accurately captures shocks and chaotic dynamics by proposing a new architecture, stabilized neural ordinary differential equation (ODE). In our proposed architecture, we learn the right-hand-side (RHS) of an ODE by adding the outputs of two NN together where one learns a linear term and the other a nonlinear term. Specifically, we implement this by training a sparse linear convolutional NN to learn the linear term and a dense fully-connected nonlinear NN to learn the nonlinear term. This contrasts with the standard neural ODE which involves training a single NN for the RHS. We apply this setup to the viscous Burgers equation, which exhibits shocked behavior, and show stabilized neural ODEs provide better short-time tracking, prediction of the energy spectrum, and robustness to noisy initial conditions than standard neural ODEs. We also apply this method to chaotic trajectories of the Kuramoto-Sivashinsky equation. In this case, stabilized neural ODEs keep long-time trajectories on the attractor, and are highly robust to noisy initial conditions, while standard neural ODEs fail at achieving either of these results. We conclude by demonstrating how stabilizing neural ODEs provide a natural extension for use in reduced-order modeling by projecting the dynamics onto the eigenvectors of the learned linear term.}
}

@article{BANERJEE20221,
title = {EnZymClass: Substrate specificity prediction tool of plant acyl-ACP thioesterases based on ensemble learning},
journal = {Current Research in Biotechnology},
volume = {4},
pages = {1-9},
year = {2022},
issn = {2590-2628},
doi = {https://doi.org/10.1016/j.crbiot.2021.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S259026282100037X},
author = {Deepro Banerjee and Michael A. Jindra and Alec J. Linot and Brian F. Pfleger and Costas D. Maranas},
keywords = {Thioesterase, Enzyme classification, Machine learning, Substrate specificity, Medium-chain oleochemicals, Synthetic biology},
abstract = {Characterizing the functional properties of plant acyl-ACP thioesterases (TEs), a key enzyme class used in the production of renewable oleochemicals in microbial hosts, experimentally, can be an expensive and time consuming process since it requires manual screening of thousands of candidates in a database. Using amino acid sequence to computationally predict an enzyme’s function might accelerate this process; however obtaining the necessary amount of information on previously characterized enzymes and their respective sequences required by standard Machine Learning (ML) based approaches to accurately infer sequence-function relationships can be prohibitive, especially with a low-throughput testing cycle. Experimental noise, unbalanced dataset where high sequence similarity does not always imply identical functional properties will further prevent robust prediction performance. Herein we present a ML method, Ensemble method for enZyme Classification (EnZymClass), that is specifically designed to address these issues. We used EnZymClass to classify TEs into short, long and mixed free fatty acid substrate specificity categories. While general guidelines for inferring substrate specificity have been proposed before, prediction of chain-length preference from primary sequence has remained elusive for plant acyl-ACP TEs. By applying EnZymClass to a subset of TEs in the ThYme database, we identified two medium chain TEs, ClFatB3 and CwFatB2, with previously uncharacterized activity in E. coli fatty acid production hosts. EnZymClass can be readily applied to other protein classification challenges and is available at: https://github.com/deeprob/ThioesteraseEnzymeSpecificity.}
}